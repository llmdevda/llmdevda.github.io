---
title: "梯度训练，信息熵与巫术占卜"
date: 2025-06-05
categories: ["实战", "教程"]
tags: [llm, grpo, openr1]
---

想象一个远古部落在丛林中，部落以打猎为生。

这里气候非常突变，如果在打猎过程中遇到突降的暴雨，轻则颗粒无收，重则损失人员。

部落里有个萨满负责占卜天气，如果天晴则部落集体外出打猎，如果下雨则留在部落不外出。

萨满每天早上作出占卜，q的概率为天晴，1-q的概率为下雨。

部落人根据萨满预测是否准确来给萨满奖励食物ri。一段时间下来，萨满就得到总奖励ri求和

萨满为了得到更多食物，就得尽可能占卜正确

随后根据是否下雨，调整概率q的值

如果今天是天晴，那么把q调大一点。

比如如果今天下雨了，那么把1-q调大一点，也就是q调小一点。

这就是梯度训练。

萨满用这方法改善预测，虽然不是很准，但也大致符合了现实。

但萨满发现每天都去调整概率太麻烦了，因为需要去削占卜的木块。

于是萨满决定一周去削一次（batch或者梯度累积）

有一天，天生异象

这天不仅下雨而且还出太阳，在部落下雨，在丛林就出太阳。

于是，萨满无论怎么预测都是正确的

那么这时？萨满怎么去调整概率最好呢？

我们依旧没有最好的方案。

我们来讨论一个方案。

首先是一个固定梯度的方案的导向极端的方案，

因为无论预测哪种都是正确的，那么萨满做出任何预测都会依据提升改预测概率方向的梯度进行。

如果此时某一方的概率大，则其出现在占卜预言的次数多，其提升的也就越多。

长此以往，概率就会走向极端。

比如萨满每次预测晴天都发现对了，雨天也发现对了，他就愈发的提升预测晴天的概率，直到一直预测晴天。

一切都很顺利，直到有一天，异变消失，新的一周全是雨天。

萨满的预测全部失败，预测失败就没有食物，萨满因为一周都没有食物而饿死了。

见证完极端方案后，我们看看相对概率的方案

相对概率时，梯度会按当前概率的倒数。

现在预测晴天的概率q，如果今天晴天，那按1/q的幅度比率去提升q的值。

比如现在q为0.1，也就是10%的概率预测天晴，那么提升的幅度比率是10

而如果现在q为0.5，那就是50%的概率，那么提升的幅度比率为2

概率越高时，调大的幅度越小。

概率越低时，调大的幅度越大。

这种策略会导向更加中庸且怀疑的选择。

随着异常天数的增加，概率会趋于一半一半，q=0.5。

萨满不确信是晴天还是雨天，他对两种天气保持相等的怀疑。

然后又到了异变消失的一天，新的一周每天都是下雨

上一个萨满因为全预测晴天而饿死了，而新的这个中庸且怀疑的萨满，有很大概率能活下来。

这就是不同梯度策略导致的不同结果

或者说不同的应对变化的结果。

当然，如果我们把条件设置的严苛一点，比如每周必须每天都吃饭才能活下来，那么可能任何策略都难以起效。

所以策略的结果也是取决于环境的严苛程度的。

在某些环境下，这种中庸的策略在过程中可能就死了，就像我们知道有时侯就得不犹豫的一股脑冲，尤其是在一些以小搏大的场景。

所以我们很难判断策略好坏。

只能说限定在易变换且具备一定容错的环境下，偏中庸相对概率梯度策略，更不易走向极端而连续失败。

中庸的概率策略其实在数学上会表现为信息熵的增大。

要计算概率分布的信息熵，我们可以使用信息熵的公式：

\[
H(X) = -\sum_{i} p_i \log_2 p_i
\]

其中，\( p_i \) 是第 \( i \) 个事件的概率，在这里就是预测晴天与下雨。

1. 概率分布 \( (0, 1) \)：

有两个事件，概率分别为 \( p_1 = 0 \) 和 \( p_2 = 1 \)。

计算信息熵：

\[
H(X) = - (0 \log_2 0 + 1 \log_2 1) = - (0 + 0) = 0
\]

因此，概率分布 \( (0, 1) \) 的信息熵是 **0 比特**。

2. 对于概率分布 \( (0.5, 0.5) \) 信息熵：

\[
H(X) = - (0.5 \log_2 0.5 + 0.5 \log_2 0.5) = - (-0.5 - 0.5) = 1
\]

因此，概率分布 \( (0.5, 0.5) \) 的信息熵是 **1 比特**。

也就是说，中庸的萨满2号，比自信的萨满1号具有更高的信息量。

更高信息量的策略，在应对不确定环境时，有更高的正确机会。

并不是正确概率，因为正确的期望是一样的。

但是萨满的时间不是无限的，在有限的时间里，中庸的策略更有机会正确。

这种机会并不是指概率期望，因为从期望而言，猜测正确与否的成功率还取决于老天。

我们用数学公式表达

q_{guess}, q_{real}

当一直猜正面时，N次至少正确一次的概率为 

$$
1-(q_real)^N
$$

当一直猜反面时，N次至少正确一次的概率为 

$$
1-(1-q_real)^N
$$

当随机猜测正反时，正确的概率则与老天无关，而是0.5，N次至少正确一次的概率为 

$$
1-(0.5)^N
$$

当q_real从0突变到1时，一直猜某面的N次至少正确概率会降低。

而随机猜测的N次正确概率则保持了一致。












